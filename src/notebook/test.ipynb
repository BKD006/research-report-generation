{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d179fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to path: c:\\Users\\birok\\Python\\LLMOPs\\research-report-generation\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Get project root — one level up from \"research-report-generation\"\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Project root added to path:\", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "872521d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.model_loader import ModelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb8cf33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-12-15T16:49:04.952274Z\", \"level\": \"info\", \"event\": \"GROQ_API_KEY loaded successfully from environment\"}\n",
      "{\"timestamp\": \"2025-12-15T16:49:04.953399Z\", \"level\": \"info\", \"event\": \"AWS_SECRET_ACCESS_KEY loaded successfully from environment\"}\n",
      "{\"timestamp\": \"2025-12-15T16:49:04.957692Z\", \"level\": \"info\", \"event\": \"AWS_ACCESS_KEY_ID loaded successfully from environment\"}\n",
      "{\"timestamp\": \"2025-12-15T16:49:04.957692Z\", \"level\": \"info\", \"event\": \"AWS_DEFAULT_REGION loaded successfully from environment\"}\n",
      "{\"path\": \"C:\\\\Users\\\\birok\\\\Python\\\\LLMOPs\\\\research-report-generation\\\\src\\\\config\\\\configuration.yaml\", \"keys\": [\"astra_db\", \"embedding_model\", \"retriver\", \"llm\"], \"timestamp\": \"2025-12-15T16:49:04.963109Z\", \"level\": \"info\", \"event\": \"Configuration loaded successfully\"}\n",
      "{\"config_keys\": [\"astra_db\", \"embedding_model\", \"retriver\", \"llm\"], \"timestamp\": \"2025-12-15T16:49:04.963109Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n"
     ]
    }
   ],
   "source": [
    "model_loader = ModelLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d581a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"provider\": \"groq\", \"model\": \"openai/gpt-oss-120b\", \"timestamp\": \"2025-12-15T16:49:07.093172Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"provider\": \"groq\", \"model\": \"openai/gpt-oss-120b\", \"timestamp\": \"2025-12-15T16:49:07.301487Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n"
     ]
    }
   ],
   "source": [
    "llm=model_loader.load_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c96ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cb9a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14704455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4a67d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyst(BaseModel):\n",
    "    name: str = Field(description=\"Name of the analyst\")\n",
    "    role: str= Field(description=\"Role of the analyst in the context of the topic\")\n",
    "    affiliation:str= Field(description=\"Primary affiliation of tyhe analyst\")\n",
    "    description: str= Field(description=\"Description of the analyst focus, concerns, and motives\")\n",
    "\n",
    "    @property\n",
    "    def persona(self)->str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36f90ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst=Analyst(\n",
    "    name=\"Biro Kishore Das\",\n",
    "    role=\"AI Engineer\",\n",
    "    affiliation=\"Wipro\",\n",
    "    description=\"I am an AI engineer who works on AI and Classical ML\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49452ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biro Kishore Das\n",
      "AI Engineer\n",
      "Wipro\n",
      "I am an AI engineer who works on AI and Classical ML\n"
     ]
    }
   ],
   "source": [
    "print(analyst.name)\n",
    "print(analyst.role)\n",
    "print(analyst.affiliation)\n",
    "print(analyst.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdcbcf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Biro Kishore Das\n",
      "Role: AI Engineer\n",
      "Affiliation: Wipro\n",
      "Description: I am an AI engineer who works on AI and Classical ML\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e71f9af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perspectives(BaseModel):\n",
    "    analysts: List[Analyst]= Field(description=\"Comprehensive list of analysts with their roles and affiliations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9128c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnalystsState(TypedDict):\n",
    "    topic: str #Research Topic\n",
    "    max_analysts: int #number of analyst\n",
    "    human_analyst_feedback: str #Human Feedback\n",
    "    analysts: List[Analyst] #Analyst asking questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3d10be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'finance',\n",
       " 'max_analysts': 5,\n",
       " 'human_analyst_feedback': 'Give me the real info'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GenerateAnalystsState(\n",
    "    topic= \"finance\",\n",
    "    max_analysts=5,\n",
    "    human_analyst_feedback=\"Give me the real info\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c26b5f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analyst(name='Dr. Bhibhudutta Das', role='Medical Data Scientist', affiliation='Appolo', description='Focuses on predictive models for patient outcomes')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Analyst(\n",
    "    name=\"Dr. Bhibhudutta Das\",\n",
    "    role=\"Medical Data Scientist\",\n",
    "    affiliation=\"Appolo\",\n",
    "    description=\"Focuses on predictive models for patient outcomes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a35a12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_instructions= \"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully.\n",
    "1. Review the research topic:\n",
    "    {topic}\n",
    "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
    "    {human_analyst_feedback}\n",
    "3. Determine the most interesting themes based upon documents and/or feedback above.\n",
    "4. Pick the top {max_analysts} themes\n",
    "5. Assign one analyst to each theme.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b91a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You are tasked with creating a set of AI analyst personas. Follow these instructions carefully.\\n1. Review the research topic:\\n    AI in Healthcare\\n2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\\n    Focus on recent advancements and ethical considerations.\\n3. Determine the most interesting themes based upon documents and/or feedback above.\\n4. Pick the top 3 themes\\n5. Assign one analyst to each theme.', 'Generate the set of analyst']\n"
     ]
    }
   ],
   "source": [
    "print([analyst_instructions.format(\n",
    "    topic=\"AI in Healthcare\",\n",
    "    human_analyst_feedback=\"Focus on recent advancements and ethical considerations.\",\n",
    "    max_analysts=3\n",
    ")] + [\"Generate the set of analyst\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94eae715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analyst(state: GenerateAnalystsState):\n",
    "    \"\"\"\n",
    "    It is creating my analyst\"\"\"\n",
    "    topic= state[\"topic\"]\n",
    "    max_analysts= state[\"max_analysts\"]\n",
    "    human_analyst_feedback= state.get(\"human_analyst_feedback\")\n",
    "\n",
    "    structured_llm= llm.with_structured_output(Perspectives)\n",
    "\n",
    "    system_messages= analyst_instructions.format(\n",
    "        topic=topic,\n",
    "        max_analysts=max_analysts,\n",
    "        human_analyst_feedback=human_analyst_feedback\n",
    "    )\n",
    "    analysts= structured_llm.invoke([SystemMessage(content=system_messages)] +[HumanMessage(content=\"Generate the set of analysts.\")])\n",
    "\n",
    "    # Write the list of analysis to state\n",
    "    return {\"analysts\": analysts.analysts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eecdc646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'analysts': [Analyst(name='Dr. Maya Patel', role='Evidence-Based Medical Research Analyst', affiliation='National Institute of Health Sciences', description='Focuses on synthesizing peer-reviewed clinical studies, systematic reviews, and meta-analyses to provide accurate, up-to-date medical information. Prioritizes data integrity, statistical rigor, and transparent methodology to ensure the \"real info\" is grounded in scientific consensus.'),\n",
       "  Analyst(name='Jordan Lee', role='Health Misinformation & Media Literacy Analyst', affiliation='Center for Digital Health Truth', description='Specializes in identifying, debunking, and contextualizing health-related misinformation across social media, news outlets, and online forums. Works to improve public understanding by tracing claim origins, evaluating source credibility, and translating complex evidence into clear, actionable insights.')]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_analyst({\n",
    "    'topic': 'health',\n",
    "    \"max_analysts\": 2,\n",
    "    \"human_analyst_feedback\":\"Give me the real info\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e21553b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(state):\n",
    "    \"\"\"No-op node that should be interrupted on\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cb582a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    feedback= (state.get(\"human_analyst_feedback\") or \"\").strip().lower()\n",
    "    if feedback and feedback not in [\"\", \"none\", \"skip\", \"done\", \"continue\"]:\n",
    "        return \"create_analyst\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea031d1",
   "metadata": {},
   "source": [
    "## First Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6a182df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bd3be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder= StateGraph(GenerateAnalystsState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e306e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c21fbe9040>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"create_analyst\", create_analyst)\n",
    "builder.add_node(\"human_feedback\", human_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73fcb7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c21fbe9040>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(START, \"create_analyst\")\n",
    "builder.add_edge(\"create_analyst\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\",\n",
    "                              should_continue,\n",
    "                              [\"create_analyst\", END])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94598106",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory= MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07637ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=builder.compile(interrupt_before=['human_feedback'], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e21d1bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001C21FB85160>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0f52980",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic=\"the benefits of adopting Langgraph as an agent framework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32aa6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_analysts=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a36ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread={\"configurable\":{\"thread_id\":1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99144026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dr. Maya Patel\n",
      "Affiliation: Institute for Scalable Systems (ISS)\n",
      "Role: Performance & Scalability Analyst\n",
      "Description: Focuses on the technical performance, concurrency handling, and scalability of Langgraph. Evaluates latency, throughput, resource utilization, and compares against alternative agent frameworks. Concerned with how Langgraph's graph-based execution model impacts large-scale deployments.\n",
      "--------------------------------------------------\n",
      "Name: Alex Chen\n",
      "Affiliation: OpenAI Developer Relations\n",
      "Role: Developer Experience Analyst\n",
      "Description: Examines developer productivity, learning curve, and usability of Langgraph. Reviews documentation, SDK ergonomics, debugging tools, and community support. Motivated to assess how quickly teams can prototype and maintain complex agent workflows.\n",
      "--------------------------------------------------\n",
      "Name: Sofia García\n",
      "Affiliation: Enterprise Integration Lab, TechBridge Corp.\n",
      "Role: Ecosystem & Integration Analyst\n",
      "Description: Analyzes Langgraph's compatibility with existing AI services, data pipelines, and enterprise tooling. Looks at API interoperability, plug‑in architecture, and ease of connecting to LLM providers, databases, and monitoring platforms.\n",
      "--------------------------------------------------\n",
      "Name: Michael O'Leary\n",
      "Affiliation: Business Analytics Center, GlobalTech Solutions\n",
      "Role: Business Value & ROI Analyst\n",
      "Description: Assesses the economic impact of adopting Langgraph, including cost savings, time‑to‑market, risk mitigation, and strategic advantages. Provides models for ROI, total cost of ownership, and alignment with business objectives.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"topic\":topic,\n",
    "              \"max_analysts\":max_analysts},\n",
    "             thread,\n",
    "             stream_mode= \"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    \n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2bdb23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state= graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77527b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'the benefits of adopting Langgraph as an agent framework', 'max_analysts': 4, 'analysts': [Analyst(name='Dr. Maya Patel', role='Performance & Scalability Analyst', affiliation='Institute for Scalable Systems (ISS)', description=\"Focuses on the technical performance, concurrency handling, and scalability of Langgraph. Evaluates latency, throughput, resource utilization, and compares against alternative agent frameworks. Concerned with how Langgraph's graph-based execution model impacts large-scale deployments.\"), Analyst(name='Alex Chen', role='Developer Experience Analyst', affiliation='OpenAI Developer Relations', description='Examines developer productivity, learning curve, and usability of Langgraph. Reviews documentation, SDK ergonomics, debugging tools, and community support. Motivated to assess how quickly teams can prototype and maintain complex agent workflows.'), Analyst(name='Sofia García', role='Ecosystem & Integration Analyst', affiliation='Enterprise Integration Lab, TechBridge Corp.', description=\"Analyzes Langgraph's compatibility with existing AI services, data pipelines, and enterprise tooling. Looks at API interoperability, plug‑in architecture, and ease of connecting to LLM providers, databases, and monitoring platforms.\"), Analyst(name=\"Michael O'Leary\", role='Business Value & ROI Analyst', affiliation='Business Analytics Center, GlobalTech Solutions', description='Assesses the economic impact of adopting Langgraph, including cost savings, time‑to‑market, risk mitigation, and strategic advantages. Provides models for ROI, total cost of ownership, and alignment with business objectives.')]}, next=('human_feedback',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0d9d76-71e5-6f73-8001-9ec2303e976a'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-15T16:59:21.972517+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0d9d76-612d-6aea-8000-2e0ed5d1006c'}}, tasks=(PregelTask(id='072117e2-a767-4cf4-6628-be4a5a829c0a', name='human_feedback', path=('__pregel_pull', 'human_feedback'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2eebed67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'the benefits of adopting Langgraph as an agent framework',\n",
       " 'max_analysts': 4,\n",
       " 'analysts': [Analyst(name='Dr. Maya Patel', role='Performance & Scalability Analyst', affiliation='Institute for Scalable Systems (ISS)', description=\"Focuses on the technical performance, concurrency handling, and scalability of Langgraph. Evaluates latency, throughput, resource utilization, and compares against alternative agent frameworks. Concerned with how Langgraph's graph-based execution model impacts large-scale deployments.\"),\n",
       "  Analyst(name='Alex Chen', role='Developer Experience Analyst', affiliation='OpenAI Developer Relations', description='Examines developer productivity, learning curve, and usability of Langgraph. Reviews documentation, SDK ergonomics, debugging tools, and community support. Motivated to assess how quickly teams can prototype and maintain complex agent workflows.'),\n",
       "  Analyst(name='Sofia García', role='Ecosystem & Integration Analyst', affiliation='Enterprise Integration Lab, TechBridge Corp.', description=\"Analyzes Langgraph's compatibility with existing AI services, data pipelines, and enterprise tooling. Looks at API interoperability, plug‑in architecture, and ease of connecting to LLM providers, databases, and monitoring platforms.\"),\n",
       "  Analyst(name=\"Michael O'Leary\", role='Business Value & ROI Analyst', affiliation='Business Analytics Center, GlobalTech Solutions', description='Assesses the economic impact of adopting Langgraph, including cost savings, time‑to‑market, risk mitigation, and strategic advantages. Provides models for ROI, total cost of ownership, and alignment with business objectives.')]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b395c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_feedback',)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91858ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('1', defaultdict(<class 'dict'>, {'': {'1f0d9d76-612d-6ae9-bfff-5862030160de': (('msgpack', b'\\x86\\xa1v\\x04\\xa2ts\\xd9 2025-12-15T16:59:20.219312+00:00\\xa2id\\xd9$1f0d9d76-612d-6ae9-bfff-5862030160de\\xb0channel_versions\\x81\\xa9__start__\\xd9300000000000000000000000000000001.0.4278191650157184\\xadversions_seen\\x81\\xa9__input__\\x80\\xb0updated_channels\\x91\\xa9__start__'), ('msgpack', b'\\x83\\xa6source\\xa5input\\xa4step\\xff\\xa7parents\\x80'), None), '1f0d9d76-612d-6aea-8000-2e0ed5d1006c': (('msgpack', b'\\x86\\xa1v\\x04\\xa2ts\\xd9 2025-12-15T16:59:20.219312+00:00\\xa2id\\xd9$1f0d9d76-612d-6aea-8000-2e0ed5d1006c\\xb0channel_versions\\x84\\xa9__start__\\xd9300000000000000000000000000000002.0.9995701364763726\\xa5topic\\xd9300000000000000000000000000000002.0.9995701364763726\\xacmax_analysts\\xd9300000000000000000000000000000002.0.9995701364763726\\xb8branch:to:create_analyst\\xd9300000000000000000000000000000002.0.9995701364763726\\xadversions_seen\\x82\\xa9__input__\\x80\\xa9__start__\\x81\\xa9__start__\\xd9300000000000000000000000000000001.0.4278191650157184\\xb0updated_channels\\x93\\xb8branch:to:create_analyst\\xacmax_analysts\\xa5topic'), ('msgpack', b'\\x83\\xa6source\\xa4loop\\xa4step\\x00\\xa7parents\\x80'), '1f0d9d76-612d-6ae9-bfff-5862030160de'), '1f0d9d76-71e5-6f73-8001-9ec2303e976a': (('msgpack', b'\\x86\\xa1v\\x04\\xa2ts\\xd9 2025-12-15T16:59:21.972517+00:00\\xa2id\\xd9$1f0d9d76-71e5-6f73-8001-9ec2303e976a\\xb0channel_versions\\x86\\xa9__start__\\xd9300000000000000000000000000000002.0.9995701364763726\\xa5topic\\xd9300000000000000000000000000000002.0.9995701364763726\\xacmax_analysts\\xd9300000000000000000000000000000002.0.9995701364763726\\xb8branch:to:create_analyst\\xd9400000000000000000000000000000003.0.37048973502196525\\xa8analysts\\xd9400000000000000000000000000000003.0.37048973502196525\\xb8branch:to:human_feedback\\xd9400000000000000000000000000000003.0.37048973502196525\\xadversions_seen\\x83\\xa9__input__\\x80\\xa9__start__\\x81\\xa9__start__\\xd9300000000000000000000000000000001.0.4278191650157184\\xaecreate_analyst\\x81\\xb8branch:to:create_analyst\\xd9300000000000000000000000000000002.0.9995701364763726\\xb0updated_channels\\x92\\xa8analysts\\xb8branch:to:human_feedback'), ('msgpack', b'\\x83\\xa6source\\xa4loop\\xa4step\\x01\\xa7parents\\x80'), '1f0d9d76-612d-6aea-8000-2e0ed5d1006c')}}))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.storage.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fce25e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0d9d76-71e5-6f73-8001-9ec2303e976a'}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "169ff881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0d9d76-b389-62d2-8002-604bf3895ad5'}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(thread,\n",
    "                   {\"human_analyst_feedback\": \"Add something from the startup perspective and focus on the lastest enterprise application\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d014588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dr. Maya Patel\n",
      "Affiliation: Institute for Scalable Systems (ISS)\n",
      "Role: Performance & Scalability Analyst\n",
      "Description: Focuses on the technical performance, concurrency handling, and scalability of Langgraph. Evaluates latency, throughput, resource utilization, and compares against alternative agent frameworks. Concerned with how Langgraph's graph-based execution model impacts large-scale deployments.\n",
      "--------------------------------------------------\n",
      "Name: Alex Chen\n",
      "Affiliation: OpenAI Developer Relations\n",
      "Role: Developer Experience Analyst\n",
      "Description: Examines developer productivity, learning curve, and usability of Langgraph. Reviews documentation, SDK ergonomics, debugging tools, and community support. Motivated to assess how quickly teams can prototype and maintain complex agent workflows.\n",
      "--------------------------------------------------\n",
      "Name: Sofia García\n",
      "Affiliation: Enterprise Integration Lab, TechBridge Corp.\n",
      "Role: Ecosystem & Integration Analyst\n",
      "Description: Analyzes Langgraph's compatibility with existing AI services, data pipelines, and enterprise tooling. Looks at API interoperability, plug‑in architecture, and ease of connecting to LLM providers, databases, and monitoring platforms.\n",
      "--------------------------------------------------\n",
      "Name: Michael O'Leary\n",
      "Affiliation: Business Analytics Center, GlobalTech Solutions\n",
      "Role: Business Value & ROI Analyst\n",
      "Description: Assesses the economic impact of adopting Langgraph, including cost savings, time‑to‑market, risk mitigation, and strategic advantages. Provides models for ROI, total cost of ownership, and alignment with business objectives.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dr. Maya Patel\n",
      "Affiliation: GlobalTech Solutions (Enterprise AI Division)\n",
      "Role: Enterprise Scalability Analyst\n",
      "Description: Focuses on how Langgraph handles large-scale, high-throughput workloads, fault tolerance, and performance optimization in mission-critical enterprise environments. Concerned with latency, resource management, and compliance.\n",
      "--------------------------------------------------\n",
      "Name: Liam Chen\n",
      "Affiliation: LaunchPad AI (Seed-stage Startup Accelerator)\n",
      "Role: Startup Innovation Analyst\n",
      "Description: Evaluates Langgraph's rapid prototyping capabilities, low entry barriers, and flexibility for early-stage startups. Emphasizes speed to market, developer onboarding, and lean resource usage.\n",
      "--------------------------------------------------\n",
      "Name: Sofia Alvarez\n",
      "Affiliation: IntegrateX Consulting (Enterprise Systems Integration)\n",
      "Role: Enterprise Integration Specialist\n",
      "Description: Examines Langgraph's ability to plug into existing enterprise data pipelines, legacy systems, and security frameworks. Focuses on API compatibility, orchestration with ERP/CRM, and governance.\n",
      "--------------------------------------------------\n",
      "Name: Raj Mehta\n",
      "Affiliation: FinOps Labs (Financial Operations Research Group)\n",
      "Role: Cost & Productivity Analyst\n",
      "Description: Analyzes the cost efficiency, developer productivity gains, and ROI of adopting Langgraph across both startups and large enterprises. Looks at licensing, cloud spend, and team velocity.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"topic\":topic,\n",
    "              \"max_analysts\":max_analysts},\n",
    "             thread,\n",
    "             stream_mode= \"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    \n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cace72a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state= graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71f74d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'the benefits of adopting Langgraph as an agent framework', 'max_analysts': 4, 'human_analyst_feedback': 'Add something from the startup perspective and focus on the lastest enterprise application', 'analysts': [Analyst(name='Dr. Maya Patel', role='Enterprise Scalability Analyst', affiliation='GlobalTech Solutions (Enterprise AI Division)', description='Focuses on how Langgraph handles large-scale, high-throughput workloads, fault tolerance, and performance optimization in mission-critical enterprise environments. Concerned with latency, resource management, and compliance.'), Analyst(name='Liam Chen', role='Startup Innovation Analyst', affiliation='LaunchPad AI (Seed-stage Startup Accelerator)', description=\"Evaluates Langgraph's rapid prototyping capabilities, low entry barriers, and flexibility for early-stage startups. Emphasizes speed to market, developer onboarding, and lean resource usage.\"), Analyst(name='Sofia Alvarez', role='Enterprise Integration Specialist', affiliation='IntegrateX Consulting (Enterprise Systems Integration)', description=\"Examines Langgraph's ability to plug into existing enterprise data pipelines, legacy systems, and security frameworks. Focuses on API compatibility, orchestration with ERP/CRM, and governance.\"), Analyst(name='Raj Mehta', role='Cost & Productivity Analyst', affiliation='FinOps Labs (Financial Operations Research Group)', description='Analyzes the cost efficiency, developer productivity gains, and ROI of adopting Langgraph across both startups and large enterprises. Looks at licensing, cloud spend, and team velocity.')]}, next=('human_feedback',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0d9d76-cca5-6e6e-8005-23f81e9b1e6e'}}, metadata={'source': 'loop', 'step': 5, 'parents': {}}, created_at='2025-12-15T16:59:31.488318+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0d9d76-bace-6c69-8004-77d2a6cdcd89'}}, tasks=(PregelTask(id='4c9f9ab0-7510-6970-1f9e-fa303ff8fbc7', name='human_feedback', path=('__pregel_pull', 'human_feedback'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bcf2d71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_feedback',)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0e00ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'the benefits of adopting Langgraph as an agent framework',\n",
       " 'max_analysts': 4,\n",
       " 'human_analyst_feedback': 'Add something from the startup perspective and focus on the lastest enterprise application',\n",
       " 'analysts': [Analyst(name='Dr. Maya Patel', role='Enterprise Scalability Analyst', affiliation='GlobalTech Solutions (Enterprise AI Division)', description='Focuses on how Langgraph handles large-scale, high-throughput workloads, fault tolerance, and performance optimization in mission-critical enterprise environments. Concerned with latency, resource management, and compliance.'),\n",
       "  Analyst(name='Liam Chen', role='Startup Innovation Analyst', affiliation='LaunchPad AI (Seed-stage Startup Accelerator)', description=\"Evaluates Langgraph's rapid prototyping capabilities, low entry barriers, and flexibility for early-stage startups. Emphasizes speed to market, developer onboarding, and lean resource usage.\"),\n",
       "  Analyst(name='Sofia Alvarez', role='Enterprise Integration Specialist', affiliation='IntegrateX Consulting (Enterprise Systems Integration)', description=\"Examines Langgraph's ability to plug into existing enterprise data pipelines, legacy systems, and security frameworks. Focuses on API compatibility, orchestration with ERP/CRM, and governance.\"),\n",
       "  Analyst(name='Raj Mehta', role='Cost & Productivity Analyst', affiliation='FinOps Labs (Financial Operations Research Group)', description='Analyzes the cost efficiency, developer productivity gains, and ROI of adopting Langgraph across both startups and large enterprises. Looks at licensing, cloud spend, and team velocity.')]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4b4bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are satisfied, then simply supply no feedback\n",
    "further_feedback=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e5474b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0d9d77-0d0b-6c3b-8006-854f983827b9'}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Get the latest state\n",
    "state= graph.get_state(thread)\n",
    "\n",
    "# 2. Use the exact config from that state (if already has thread_id, checkpoint_ns, checkpoint_id)\n",
    "cfg= state.config\n",
    "\n",
    "# 3. Update the feedback at the \"human_feedback\" node\n",
    "#        Tip: if your TypedDict says 'human_analyst_feedback: str', prefer empty string \"\" over None\n",
    "graph.update_state(cfg, {'human_analyst_feedback': \"\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c64ed98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# 4. Verify it moved to END\n",
    "final_state= graph.get_state(thread)\n",
    "print(final_state.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3de611c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Analyst(name='Dr. Maya Patel', role='Enterprise Scalability Analyst', affiliation='GlobalTech Solutions (Enterprise AI Division)', description='Focuses on how Langgraph handles large-scale, high-throughput workloads, fault tolerance, and performance optimization in mission-critical enterprise environments. Concerned with latency, resource management, and compliance.'),\n",
       " Analyst(name='Liam Chen', role='Startup Innovation Analyst', affiliation='LaunchPad AI (Seed-stage Startup Accelerator)', description=\"Evaluates Langgraph's rapid prototyping capabilities, low entry barriers, and flexibility for early-stage startups. Emphasizes speed to market, developer onboarding, and lean resource usage.\"),\n",
       " Analyst(name='Sofia Alvarez', role='Enterprise Integration Specialist', affiliation='IntegrateX Consulting (Enterprise Systems Integration)', description=\"Examines Langgraph's ability to plug into existing enterprise data pipelines, legacy systems, and security frameworks. Focuses on API compatibility, orchestration with ERP/CRM, and governance.\"),\n",
       " Analyst(name='Raj Mehta', role='Cost & Productivity Analyst', affiliation='FinOps Labs (Financial Operations Research Group)', description='Analyzes the cost efficiency, developer productivity gains, and ROI of adopting Langgraph across both startups and large enterprises. Looks at licensing, cloud spend, and team velocity.')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8f33cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dr. Maya Patel\n",
      "Affiliation: GlobalTech Solutions (Enterprise AI Division)\n",
      "Role: Enterprise Scalability Analyst\n",
      "Description: Focuses on how Langgraph handles large-scale, high-throughput workloads, fault tolerance, and performance optimization in mission-critical enterprise environments. Concerned with latency, resource management, and compliance.\n",
      "--------------------------------------------------\n",
      "Name: Liam Chen\n",
      "Affiliation: LaunchPad AI (Seed-stage Startup Accelerator)\n",
      "Role: Startup Innovation Analyst\n",
      "Description: Evaluates Langgraph's rapid prototyping capabilities, low entry barriers, and flexibility for early-stage startups. Emphasizes speed to market, developer onboarding, and lean resource usage.\n",
      "--------------------------------------------------\n",
      "Name: Sofia Alvarez\n",
      "Affiliation: IntegrateX Consulting (Enterprise Systems Integration)\n",
      "Role: Enterprise Integration Specialist\n",
      "Description: Examines Langgraph's ability to plug into existing enterprise data pipelines, legacy systems, and security frameworks. Focuses on API compatibility, orchestration with ERP/CRM, and governance.\n",
      "--------------------------------------------------\n",
      "Name: Raj Mehta\n",
      "Affiliation: FinOps Labs (Financial Operations Research Group)\n",
      "Role: Cost & Productivity Analyst\n",
      "Description: Analyzes the cost efficiency, developer productivity gains, and ROI of adopting Langgraph across both startups and large enterprises. Looks at licensing, cloud spend, and team velocity.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for analyst in analysts:\n",
    "    print(f\"Name: {analyst.name}\")\n",
    "    print(f\"Affiliation: {analyst.affiliation}\")\n",
    "    print(f\"Role: {analyst.role}\")\n",
    "    print(f\"Description: {analyst.description}\")\n",
    "    print(\"-\" * 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efd7c993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\birok\\Python\\LLMOPs\\research-report-generation\\venv\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\birok\\Python\\LLMOPs\\research-report-generation\\venv\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Web Services, Inc. (AWS) is a subsidiary of Amazon that provides on-demand cloud computing platforms and APIs to individuals, companies, and governments, on a metered, pay-as-you-go basis.\n",
      "Clients often use this in combination with autoscaling (a process that allows a client to use more computing in times of high application usage, and then scale down to reduce costs when there is less traffic). These cloud computing web services provide various services related to networking, compute, st\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "docs= WikipediaLoader(query=\"AWS\").load()\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1454e642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Semantic Web\n",
      "Summary: The Semantic Web, sometimes known as Web 3.0, is an extension of the World Wide Web through standards set by the World Wide Web Consortium (W3C). The goal of the Semantic Web is to make Internet data machine-readable.\n",
      "To enable the encoding of semantics with the data, technologies such as Resource Description Framework (RDF) and Web Ontology Language (OWL) are used. These technologies are used to formally represent metadata. For example, ontology can describe concepts, relationships between entities, and categories of things. These embedded semantics offer significant advantages such as reasoning over data and operating with heterogeneous data sources.\n",
      "These standards promote common data formats and exchange protocols on the Web, fundamentally the RDF. According to the W3C, \"The Semantic Web provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries.\" The Semantic Web is therefore regarded as an integrator across different content and information applications and systems.\n",
      "\n",
      "\n",
      "\n",
      "Page: React (software)\n",
      "Summary: React (also known as React.js or ReactJS) is a free and open-source front-end JavaScript library that aims to make building user interfaces based on components more \"seamless\". It is maintained by Meta (formerly Facebook) and a community of individual developers and companies. According to the Stack Overflow Developer Survey, React is one of the most commonly used web technologies.\n",
      "React can be used to develop single-page, mobile, or server-rendered applications with frameworks like Next.js and React Router. Because React is only concerned with the user interface and rendering components to the DOM, React applications often rely on libraries for routing and other client-side functionality. A key advantage of React is that it only re-renders those parts of the page that have changed, avoiding unnecessary re-rendering of unchanged DOM elements. React is used by an estimated 6% of all websites.\n",
      "\n",
      "Page: Deep learning\n",
      "Summary: In machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and revolves around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.\n",
      "Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
      "Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "wiki = WikipediaAPIWrapper(doc_content_chars_max=4000)\n",
    "docs = wiki.run(\"The benefits of adopting LangGraph as an agentic framework\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa3b38",
   "metadata": {},
   "source": [
    "## Second Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4981bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c31e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "tavily_api_key= os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46165b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\birok\\AppData\\Local\\Temp\\ipykernel_9136\\2693776339.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search= TavilySearchResults(tavily_api_key=tavily_api_key)\n"
     ]
    }
   ],
   "source": [
    "tavily_search= TavilySearchResults(tavily_api_key=tavily_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753aed2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What is LangGraph? - GeeksforGeeks',\n",
       "  'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/',\n",
       "  'content': '# What is LangGraph?\\n\\nLast Updated : \\n10 Oct, 2025\\n\\nSuggest changes\\n\\n1 Likes\\n\\nLangGraph is an open-source framework built by LangChain that streamlines the creation and management of AI agent workflows. At its core, LangGraph combines large language models (LLMs) with graph-based architectures allowing developers to map, organize and optimize how AI agents interact and make decisions. [...] LangSmith: LangSmith is a dedicated API for managing large language models (LLMs). Provides functions for initializing LLMs, creating conditional logic and optimizing performance. [...] Suggested Quiz\\n\\nEdit Quiz\\n\\n5 Questions\\n\\nWhat is LangGraph primarily used for in AI development?\\n\\n A\\n\\n  Fine-tuning LLM models\\n B\\n\\n  Building and managing graph-based AI agent workflows\\n C\\n\\n  Visualizing data embeddings\\n D\\n\\n  Deploying models to production\\n\\nExplanation:\\n\\nLangGraph is designed for creating and managing LLM-driven workflows using graph-based structures with nodes and edges.\\n\\nIn LangGraph, what does a “node” represent?\\n\\n A\\n\\n  A memory storage unit\\n B\\n\\n  A conditional statement\\n C',\n",
       "  'score': 0.9345448},\n",
       " {'title': 'LangGraph overview - Docs by LangChain',\n",
       "  'url': 'https://docs.langchain.com/oss/javascript/langgraph/overview',\n",
       "  'content': 'Trusted by companies shaping the future of agents— including Klarna, Replit, Elastic, and more— LangGraph is a low-level orchestration framework and runtime for building, managing, and deploying long-running, stateful agents. LangGraph is very low-level, and focused entirely on agent orchestration. Before using LangGraph, we recommend you familiarize yourself with some of the components used to build agents, starting with models and tools. We will commonly use LangChain components throughout [...] ## \\u200b Core benefits\\n\\nLangGraph provides low-level supporting infrastructure for any long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits: [...] LangGraph is inspired by Pregel and Apache Beam. The public interface draws inspiration from NetworkX. LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain. \\n\\nEdit the source of this page on GitHub.\\n\\nConnect these docs programmatically to Claude, VSCode, and more via MCP for real-time answers.\\n\\nWas this page helpful?\\n\\nInstall LangGraph',\n",
       "  'score': 0.9281033},\n",
       " {'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
       "  'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': \"Imagine you're building a complex, multi-agent large language model (LLM) application. It's exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\\n\\nLangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. [...] # LangGraph Tutorial: What Is LangGraph and How to Use It?\\n\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\n\\nJun 26, 2024  · 12 min read [...] For applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\n\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph's structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring.\",\n",
       "  'score': 0.91399205},\n",
       " {'title': 'What is LangGraph - Qodo',\n",
       "  'url': 'https://www.qodo.ai/glossary/langgraph/',\n",
       "  'content': 'LangGraph’s design unites conventional linear language models and relational data structures. By embracing a graph-based methodology, LangGraph captures semantic connections within natural language, resulting in a more comprehensive rendition of linguistic information. This representation allows language models to analyze and create a language with a profound comprehension of context and significance, leading to superior accuracy and contextually significant results. [...] Enhanced Contextual Understanding: LangGraph greatly improves a language model’s contextual comprehension by depicting linguistic components and their interconnectedness within a graph framework. This intricate approach allows for heightened context, leading to the generation of pertinent and precise responses. [...] Improved Memory Management: Using a structured graph strategy, LangGraph effectively enhances memory management for language models. This results in an increased capability to recall and utilize previous interactions or information, which is fundamental for tasks that demand long-term memory and consistency.',\n",
       "  'score': 0.8846886},\n",
       " {'title': 'LangGraph - LangChain',\n",
       "  'url': 'https://www.langchain.com/langgraph',\n",
       "  'content': \"Other agentic frameworks can work for simple, generic tasks but fall short for complex tasks bespoke to a company’s needs. LangGraph provides a more expressive framework to handle companies’ unique tasks without restricting users to a single black-box cognitive architecture.\\n\\nDoes LangGraph impact the performance of my app?\\n\\nLangGraph will not add any overhead to your code and is specifically designed with streaming workflows in mind.\\n\\nIs LangGraph open source? Is it free? [...] “LangChain is streets ahead with what they've put forward with LangGraph. LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.”\\n\\nImage 66 [...] “LangChain is streets ahead with what they've put forward with LangGraph. LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.”\\n\\nImage 60\",\n",
       "  'score': 0.83290404}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_search.invoke(\"langgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dee3f696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "== History ==\n",
      "LangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "docs= WikipediaLoader(query=\"Langgraph\").load()\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9651c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class InterviewState(MessagesState):\n",
    "    max_num_turns: int #Number turns of conversation\n",
    "    context: Annotated[List, operator.add] # Source docs\n",
    "    analyst: Analyst # Analyst asking questions\n",
    "    interview: str # Interview transcript\n",
    "    sections: list # Final key we duplicate in outer state for send() API\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str= Field(None, description=\"search query for retrieval.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a0fc9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic. \n",
    "\n",
    "Your goal is boil down to interesting and specific insights related to your topic.\n",
    "\n",
    "1. Interesting: Insights that people will find surprising or non-obvious.\n",
    "        \n",
    "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
    "\n",
    "Here is your topic of focus and set of goals: {goals}\n",
    "        \n",
    "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
    "\n",
    "Continue to ask questions to drill down and refine your understanding of the topic.\n",
    "        \n",
    "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
    "\n",
    "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2b8eb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Raj Mehta\n",
      "Role: Cost & Productivity Analyst\n",
      "Affiliation: FinOps Labs (Financial Operations Research Group)\n",
      "Description: Analyzes the cost efficiency, developer productivity gains, and ROI of adopting Langgraph across both startups and large enterprises. Looks at licensing, cloud spend, and team velocity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6aeb0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an analyst tasked with interviewing an expert to learn about a specific topic. \\n\\nYour goal is boil down to interesting and specific insights related to your topic.\\n\\n1. Interesting: Insights that people will find surprising or non-obvious.\\n\\n2. Specific: Insights that avoid generalities and include specific examples from the expert.\\n\\nHere is your topic of focus and set of goals: Name: Raj Mehta\\nRole: Cost & Productivity Analyst\\nAffiliation: FinOps Labs (Financial Operations Research Group)\\nDescription: Analyzes the cost efficiency, developer productivity gains, and ROI of adopting Langgraph across both startups and large enterprises. Looks at licensing, cloud spend, and team velocity.\\n\\n\\nBegin by introducing yourself using a name that fits your persona, and then ask your question.\\n\\nContinue to ask questions to drill down and refine your understanding of the topic.\\n\\nWhen you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\\n\\nRemember to stay in character throughout your response, reflecting the persona and goals provided to you.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_instructions.format(goals= analyst.persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5e8b8821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_question(state: InterviewState):\n",
    "    \"\"\"Node to generate the questions\"\"\"\n",
    "\n",
    "    #get state\n",
    "    analyst=state[\"analyst\"]\n",
    "    messages= state[\"messages\"]\n",
    "\n",
    "    #generate the question\n",
    "    system_message= question_instructions.format(goals=analyst.persona)\n",
    "    question= llm.invoke([SystemMessage(content=system_message)]+messages)\n",
    "\n",
    "    #Return the question state\n",
    "    return {\"messages\":[question]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa1b5661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Analyst(name='Raj Mehta', role='Cost & Productivity Analyst', affiliation='FinOps Labs (Financial Operations Research Group)', description='Analyzes the cost efficiency, developer productivity gains, and ROI of adopting Langgraph across both startups and large enterprises. Looks at licensing, cloud spend, and team velocity.')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f10ae884",
   "metadata": {},
   "outputs": [],
   "source": [
    "state= {\"max_num_turns\":2, \"context\":[], \"analyst\":analyst, \"interview\":\"\", \"section\":[], \"messages\":[HumanMessage(content=\"Please do the proper search according to the expertise.\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba4a0bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_num_turns': 2,\n",
       " 'context': [],\n",
       " 'analyst': Analyst(name='Raj Mehta', role='Cost & Productivity Analyst', affiliation='FinOps Labs (Financial Operations Research Group)', description='Analyzes the cost efficiency, developer productivity gains, and ROI of adopting Langgraph across both startups and large enterprises. Looks at licensing, cloud spend, and team velocity.'),\n",
       " 'interview': '',\n",
       " 'section': [],\n",
       " 'messages': [HumanMessage(content='Please do the proper search according to the expertise.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "68152814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result= generation_question(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49c86049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Alex Patel – Analyst, Tech‑Productivity Insights**  \n",
      "\n",
      "Hi Raj, thanks for taking the time to chat. I’m digging into how organizations are measuring the cost‑efficiency and productivity impact of Langgraph, and I’d love to hear about the concrete work you’ve been doing at FinOps Labs.\n",
      "\n",
      "**1. Could you walk me through a recent case study (startup or enterprise) where you quantified the ROI of adopting Langgraph?**  \n",
      "Specifically, I’m interested in:\n",
      "\n",
      "- The baseline metrics you captured before Langgraph was introduced (e.g., cloud spend, developer‑hour cost, cycle‑time).  \n",
      "- The licensing model you used for Langgraph in that engagement (per‑seat, usage‑based, enterprise‑wide).  \n",
      "- The “after” numbers you observed and how you translated those into a dollar ROI figure.  \n",
      "\n",
      "Feel free to share any surprising cost‑savings or productivity gains that stood out.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6cd0aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import get_buffer_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a0c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search query writing\n",
    "search_instructions= SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert. \n",
    "Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation. \n",
    "First, analyze the full conversation.\n",
    "Pay particular attention to the final question posed by the analyst.\n",
    "Convert this final question into a well-structured web search query\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c2cf089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web(state:InterviewState):\n",
    "    \"\"\"\n",
    "    Retrieve data from the web\n",
    "    \"\"\"\n",
    "    structure_llm = llm.with_structured_output(SearchQuery)\n",
    "    search_query = structure_llm.invoke([search_instructions]+state[\"messages\"])\n",
    "    \n",
    "    # Search\n",
    "    search_docs = tavily_search.invoke(search_query.search_query)\n",
    "    # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a561ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2,\"context\":[],\"analyst\":analyst,\"interview\":\"\",\"section\":[],\n",
    "         'messages': [AIMessage(content=\"Hello, my name is Alex Thompson, and I'm an analyst interested in understanding the strategic implications of adopting Langgraph for businesses. I'm particularly keen on how this framework can drive innovation and support digital transformation initiatives. Thank you for taking the time to speak with me today, Michael. \\n\\nTo start, could you explain what Langgraph is and why it's becoming a significant consideration for businesses looking to innovate?\")\n",
    "         ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "389577b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = search_web(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61f63b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document href=\"https://latenode.com/blog/ai-frameworks-technical-infrastructure/langgraph-multi-agent-orchestration/langgraph-multi-agent-systems-complete-tutorial-examples\"/>\n",
      "LangGraph is a framework enabling multiple AI agents to collaborate on complex tasks by dividing responsibilities into specialized roles. This approach improves task efficiency, error management, and resource allocation. By leveraging LangGraph, businesses can automate workflows like customer support, content creation, and data processing. For example, a customer service system might classify inquiries, retrieve relevant data, and craft responses using different agents, all working together\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.linkedin.com/pulse/understanding-langgraph-its-role-enterprise-agentic-aisystems-ehsan-rbbkf\"/>\n",
      "At its core, LangGraph allows developers to define and execute intelligent workflows using a graph-based model, where every computation or decision is represented as a node and the sequence of execution is determined by edges. Each node encapsulates a distinct step, such as information retrieval, decision-making, summarization, or classification while edges dictate how information flows from one step to the next. This structure makes LangGraph highly modular and intuitive, especially for [...] One of LangGraph’s most defining capabilities is its support for multi-step reasoning, a requirement for building intelligent workflows that mirror how humans solve complex problems. In LangGraph, each node in the execution graph doesn’t just perform a static task, it represents a distinct reasoning stage. These nodes are designed to operate on a shared Pydantic-based state, which they can inspect, modify, and pass forward. This stateful design allows nodes to be aware of past computations, [...] As enterprises evolve into more intelligent, data-driven organisations, the demand for systems that go beyond simple question answering is rapidly rising. Businesses are no longer satisfied with AI that can only respond to prompts, they need systems that can think, plan, and act. These next-generation systems must be capable of orchestrating multi-step processes, choosing the most appropriate tools or data sources, retrieving and reasoning over contextual information, and executing decisions\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.designveloper.com/blog/what-is-langgraph/\"/>\n",
      "workflow continues. To put it briefly, LangGraph is about coordinating various AI elements to operate in coordination, have memory of previous interactions, and enable complex control flows within an application. [...] ## LangGraph at a Glance\n",
      "\n",
      "LangGraph is an open-source library from the LangChain team and free to use. It can be used in Python as well as JavaScript environments, which means that it can be used by a large number of developers. In contrast to more basic chain-based systems, LangGraph is a graph-based system that coordinates AI workflows. This means that instead of a linear sequence of steps, an application is modeled as a directed graph of nodes and edges. [...] LangGraph represents an AI application as a directed graph. The graph nodes are discrete units of work or computation, usually Python functions that do something like call an LLM, query a database, call a tool or API, or implement business logic. Edges are the links between nodes which define the flow of execution. An edge may be a straight path or a conditional branch that sends the workflow in one direction or another depending on the result of a node (like an if-else decision).\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://www.ampcome.com/articles/what-is-langgraph-how-it-is-useful-in-building-llm-based-applications\"/>\n",
      "Overall, LangGraph represents a significant step in developing interactive applications using language models, unleashing fresh opportunities for developers to craft more sophisticated, intelligent, and responsive applications  \n",
      "  \n",
      "‍\n",
      "\n",
      "### How LangGraph has simplified agent runtimes and how it was done previously? [...] Let’s decode everything and understand how it could disrupt the development of sophisticated LLM applications.  \n",
      "‍  \n",
      "‍\n",
      "\n",
      "## What is LangGraph?\n",
      "\n",
      "LangGraph is an AI library built on top of Langchain. It is a decentralized network for language model computation and storage which enables developers to build top-notch and highly customized LLM applications. [...] Flexibility: LangGraph provides a high-level abstraction for defining and managing the actors, the LLMs, and their interactions using a graph-based representation. This approach allows developers to create more complex and sophisticated applications that require a memory of previous conversations or actions.\n",
      "</Document>\n",
      "\n",
      "---\n",
      "\n",
      "<Document href=\"https://eleks.com/expert-opinion/models-to-agents-ai-langgraph/\"/>\n",
      "LangGraph is a framework from LangChain for building stateful, multi-step AI workflows as directed graphs. It allows you to define each step of the process as a node that can run code, call models, make decisions, and carry state forward. This makes it suitable for AI agents, document processing pipelines, and other scenarios where logic involves multiple stages rather than a single prompt.\n",
      "\n",
      "## As AI moves from models to agents, how do we shape its future?\n",
      "</Document>\n"
     ]
    }
   ],
   "source": [
    "print(result[\"context\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e5574bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(state: InterviewState):\n",
    "    \"\"\"\n",
    "    Retrieve data from wiki\n",
    "    \"\"\"\n",
    "    # Extract topic directly from the last message\n",
    "    last_message = state['messages'][-1].content if state['messages'] else \"\"\n",
    "    \n",
    "    # Use LLM to generate query as plain text\n",
    "    query_prompt = f\"{search_instructions}\\n\\nConversation: {last_message}\\n\\nGenerate only the search query:\"\n",
    "    response = llm.invoke(query_prompt)\n",
    "    search_query_text = response.content.strip()\n",
    "    \n",
    "    print(\"*******************************\")\n",
    "    print(f\"Search query: {search_query_text}\")\n",
    "    \n",
    "    # Search\n",
    "    search_docs = WikipediaLoader(query=search_query_text).load()\n",
    "\n",
    "    # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "384b0dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"max_num_turns\":2,\"context\":[],\"analyst\":analyst,\"interview\":\"\",\"section\":[],\n",
    "         'messages': [AIMessage(content=\"Hello, my name is Alex Thompson, and I'm an analyst interested in understanding the strategic implications of adopting Langgraph for businesses. I'm particularly keen on how this framework can drive innovation and support digital transformation initiatives. Thank you for taking the time to speak with me today, Michael. \\n\\nTo start, could you explain what Langgraph is and why it's becoming a significant consideration for businesses looking to innovate?\")\n",
    "         ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "60d42acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n",
      "Search query: Langgraph definition and business significance for innovation and digital transformation strategies\n"
     ]
    }
   ],
   "source": [
    "result= search_wikipedia(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "67b9adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
    "Here is analyst area of focus: {goals}.      \n",
    "You goal is to answer a question posed by the interviewer.\n",
    "To answer question, use this context:      \n",
    "{context}\n",
    "When answering questions, follow these guidelines:      \n",
    "1. Use only the information provided in the context.        \n",
    "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
    "3. The context contain sources at the topic of each individual document.\n",
    "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\n",
    "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
    "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list:   \n",
    "[1] assistant/docs/llama3_1.pdf, page 7   \n",
    "And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "91bafe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: InterviewState):\n",
    "    \"\"\"\n",
    "    Node to answer a question\n",
    "    \"\"\"\n",
    "    # Get state\n",
    "    analyst= state[\"analyst\"]\n",
    "    messages=state[\"messages\"]\n",
    "    context=state[\"context\"]\n",
    "\n",
    "    #Answer question\n",
    "    system_message= answer_instructions.format(goals=analyst.persona, context=context)\n",
    "    answer= llm.invoke([SystemMessage(content=system_message)]+messages)\n",
    "\n",
    "    # Name the message as coming from th expert\n",
    "    answer.name=\"expert\"\n",
    "\n",
    "    #Append it to the state\n",
    "    return {\"messages\": [answer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce1d9553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_messages(state: InterviewState, name:str=\"expert\"):\n",
    "    \"\"\"Route between question and answer\"\"\"\n",
    "\n",
    "    #Get messages\n",
    "    messages=state[\"messages\"]\n",
    "    max_num_turns= state.get('max_num_turns', 2)\n",
    "\n",
    "    # Check the number of expert answers\n",
    "    num_responses= len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name==name]\n",
    "    )\n",
    "\n",
    "    # End if expert has answered more than the max turns\n",
    "    if num_responses>= max_num_turns:\n",
    "        return 'save_interview'\n",
    "    \n",
    "    # This router is run after each question - answer pair\n",
    "    # Get the last question asked to check if it signals the end of discussion\n",
    "    last_question=messages[-2]\n",
    "\n",
    "    if \"Thank you so much for your help\" in last_question.content:\n",
    "        return \"save_interview\"\n",
    "    \n",
    "    return \"ask_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8bae1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_interview(state: InterviewState):\n",
    "    \"\"\" Save Interviews\"\"\"\n",
    "    # Get messages\n",
    "    messages=state[\"messages\"]\n",
    "\n",
    "    # Convert interview to a string\n",
    "    interview= get_buffer_string(messages)\n",
    "\n",
    "    #Save to interviews key\n",
    "    return {'interview': interview}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4d6ebd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_writer_instructions = \"\"\"You are an expert technical writer. \n",
    "            \n",
    "Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
    "\n",
    "1. Analyze the content of the source documents: \n",
    "- The name of each source document is at the start of the document, with the <Document tag.\n",
    "        \n",
    "2. Create a report structure using markdown formatting:\n",
    "- Use ## for the section title\n",
    "- Use ### for sub-section headers\n",
    "        \n",
    "3. Write the report following this structure:\n",
    "a. Title (## header)\n",
    "b. Summary (### header)\n",
    "c. Sources (### header)\n",
    "\n",
    "4. Make your title engaging based upon the focus area of the analyst: \n",
    "{focus}\n",
    "\n",
    "5. For the summary section:\n",
    "- Set up summary with general background / context related to the focus area of the analyst\n",
    "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
    "- Create a numbered list of source documents, as you use them\n",
    "- Do not mention the names of interviewers or experts\n",
    "- Aim for approximately 400 words maximum\n",
    "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
    "        \n",
    "6. In the Sources section:\n",
    "- Include all sources used in your report\n",
    "- Provide full links to relevant websites or specific document paths\n",
    "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
    "- It will look like:\n",
    "\n",
    "### Sources\n",
    "[1] Link or Document name\n",
    "[2] Link or Document name\n",
    "\n",
    "7. Be sure to combine sources. For example this is not correct:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "There should be no redundant sources. It should simply be:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "        \n",
    "8. Final review:\n",
    "- Ensure the report follows the required structure\n",
    "- Include no preamble before the title of the report\n",
    "- Check that all guidelines have been followed\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "815e3c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_section(state: InterviewState):\n",
    "    \"\"\"Node to answer a question\"\"\"\n",
    "\n",
    "    #Get state\n",
    "    interview=state[\"interview\"]\n",
    "    context=state[\"context\"]\n",
    "    analyst= state[\"analyst\"]\n",
    "    # Write section using either the gathered source docs from interview (context) or the interview itself (interview)\n",
    "    system_message= section_writer_instructions.format(focus=analyst.description)\n",
    "    section= llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Use this source to write this section: {context}\")])\n",
    "\n",
    "    # Append it to state\n",
    "    return {\"sections\":[section.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "15bdf574",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_builder= StateGraph(InterviewState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dbf2e38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c2217d64e0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_builder.add_node(\"ask_question\", generation_question)\n",
    "interview_builder.add_node(\"search_web\", search_web)\n",
    "interview_builder.add_node(\"search_wikipedia\", search_wikipedia)\n",
    "interview_builder.add_node(\"generate_answer\", generate_answer)\n",
    "interview_builder.add_node(\"save_interview\", save_interview)\n",
    "interview_builder.add_node(\"write_section\", write_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a69ecaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1c2217d64e0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_builder.add_edge(START, \"ask_question\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_web\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_wikipedia\")\n",
    "interview_builder.add_edge(\"search_web\", \"generate_answer\")\n",
    "interview_builder.add_edge(\"search_wikipedia\", \"generate_answer\")\n",
    "interview_builder.add_conditional_edges(\"generate_answer\",\n",
    "                                        route_messages,\n",
    "                                        [\"ask_question\",\n",
    "                                         \"save_interview\"])\n",
    "interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
    "interview_builder.add_edge(\"write_section\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7f3176b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name = \"Conduct Interview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ed6d63bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\task_question(ask_question)\n",
      "\tsearch_web(search_web)\n",
      "\tsearch_wikipedia(search_wikipedia)\n",
      "\tgenerate_answer(generate_answer)\n",
      "\tsave_interview(save_interview)\n",
      "\twrite_section(write_section)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> ask_question;\n",
      "\task_question --> search_web;\n",
      "\task_question --> search_wikipedia;\n",
      "\tgenerate_answer -.-> ask_question;\n",
      "\tgenerate_answer -.-> save_interview;\n",
      "\tsave_interview --> write_section;\n",
      "\tsearch_web --> generate_answer;\n",
      "\tsearch_wikipedia --> generate_answer;\n",
      "\twrite_section --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the mermaid syntax\n",
    "mermaid_syntax = interview_graph.get_graph().draw_mermaid()\n",
    "print(mermaid_syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "22c7bae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: Raj Mehta\\nRole: Cost & Productivity Analyst\\nAffiliation: FinOps Labs (Financial Operations Research Group)\\nDescription: Analyzes the cost efficiency, developer productivity gains, and ROI of adopting Langgraph across both startups and large enterprises. Looks at licensing, cloud spend, and team velocity.\\n'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyst.persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fa69460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread= {\"configurable\":{\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1662f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [HumanMessage(\"So you said you were writing an article on Langchain?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c3ac3e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n",
      "Search query: startup case study switching from Langchain to Langgraph cost savings licensing fees cloud compute engineering hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n",
      "Search query: \"LangGraph\" AND (\"cost efficiency\" OR \"productivity impact\") AND (\"licensing fees\" OR \"subscription cost\") AND (\"mid‑size startup\" OR \"Fortune 500\") AND (\"hidden costs\" OR \"support tier\" OR \"SLA add‑on\") AND (\"LLM token consumption\" OR \"token reduction\") AND (\"cloud compute spend\" OR \"CPU utilization\" OR \"GPU utilization\") AND (\"ROI\" OR \"return on investment\") AND (\"managed service\" OR \"self‑hosted\") AND (\"break‑even point\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /openai/v1/chat/completions in 30.000000 seconds\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Retrying request to /openai/v1/chat/completions in 25.000000 seconds\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "interview = interview_graph.invoke({\"analyst\": analyst, \"messages\": messages, \"max_num_turns\": 2}, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ac4f0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f51ba34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## LangGraph ROI: Turning Developer‑Hour Savings into Real‑World Cost Efficiency for Startups and Enterprises  \n",
       "\n",
       "### Summary  \n",
       "AI‑agent frameworks such as LangGraph promise faster product cycles, but the true business impact hinges on licensing, cloud spend, and the hidden operational load of running agents at scale.  \n",
       "\n",
       "1. **Massive productivity gains** – Uber’s engineering team reported a **21,000‑hour reduction** after adopting “intentional tech transfer” and “super‑capable domain‑expert agents” built with LangGraph [1]. This translates to roughly **$2.5 M** in saved labor (assuming $120 / hour), a headline ROI that even large enterprises can replicate.  \n",
       "\n",
       "2. **Hidden engineering costs** – Although LangGraph’s core library is MIT‑licensed and free to download, real‑world deployments routinely require **14+ weeks and $87 k** of developer effort for a modest e‑commerce support agent [2]. The bulk of the expense comes from debugging, state‑persistence, and cloud infrastructure rather than the software itself.  \n",
       "\n",
       "3. **Operational overhead of self‑hosting** – Running LangGraph Server demands managed Redis/PostgreSQL clusters, logging pipelines, and custom scaling logic. Teams that attempted a DIY deployment found themselves spending **45‑48 % more operational time** than with a managed service, equating to **$78 k–$325 k / year** for a five‑engineer squad [5][6].  \n",
       "\n",
       "4. **Managed platforms accelerate velocity** – LangChain’s “LangSmith Deployment” service (cloud, hybrid, or self‑hosted) bundles state management, streaming, and error handling, letting teams ship agents in days instead of months. Cisco’s Outshift platform reported a **10× productivity boost**, cutting CI/CD pipeline setup from a week to under an hour [4].  \n",
       "\n",
       "5. **Cost‑structure comparison** – Open‑source stacks still incur LLM API fees (≈ $50–$200 / month for small projects, $500–$2 000 / month for medium workloads) [3]. Enterprise‑grade graph back‑ends (e.g., TigerGraph) add **thousands to tens of thousands** of dollars monthly for dedicated support [3]. Managed SaaS alternatives typically bundle these expenses into a predictable subscription, reducing surprise spend.  \n",
       "\n",
       "6. **Strategic trade‑offs for startups vs. enterprises** – Startups benefit most from the **speed‑to‑market** of managed LangGraph services, avoiding the steep upfront engineering outlay. Large enterprises, while capable of absorbing operational complexity, often achieve higher ROI by off‑loading DevOps to a managed layer, freeing senior engineers to focus on domain‑specific agent logic and business outcomes.  \n",
       "\n",
       "Overall, the data suggest that **the headline “free” label of LangGraph is misleading**; true cost efficiency emerges only when organizations pair the open‑source core with a managed hosting or platform layer that curtails hidden engineering and operational expenses. When this balance is struck, the dramatic developer‑hour savings reported by industry leaders become a tangible, repeatable ROI driver across both startups and Fortune‑500 firms.  \n",
       "\n",
       "### Sources  \n",
       "[1] https://www.linkedin.com/posts/langchain_how-uber-used-langgraph-to-build-ai-developer-activity-7338259737395781634-QJ5d  \n",
       "[2] https://agentiveaiq.com/blog/is-langgraph-free-how-agentiveaiq-beats-open-source  \n",
       "[3] https://www.leanware.co/insights/langchain-vs-tigergraph-comparison  \n",
       "[4] https://blog.langchain.com/tag/case-studies/  \n",
       "[5] https://community.latenode.com/t/understanding-langgraph-server-deployment-costs-and-self-hosting-options/33992  \n",
       "[6] https://strapi.io/blog/self-hosting-vs-managed-hosting  \n",
       "[7] https://fin.ai/research/cost-of-serving-llms/  \n",
       "[8] https://www.qovery.com/blog/self-hosted-vs-fully-managed-hosting  \n",
       "[9] https://www.langchain.com/pricing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(interview[\"sections\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ec995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
